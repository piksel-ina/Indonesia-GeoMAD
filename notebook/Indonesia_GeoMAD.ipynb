{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Indonesia GeoMAD Notebook\n",
    "subtitle: Testing ODC-Stats Configuration for Cloud Cover Optimization and Picking the Right Study and Testing Area\n",
    "date: 2025-11-13\n",
    "authors:\n",
    "  - name: Muhammad Taufik\n",
    "    affiliations:\n",
    "      - Badan Informasi Geospasial (BIG)\n",
    "    email: muhammad.taufik@big.go.id\n",
    "  - name: Fang Yuan\n",
    "    affiliations:\n",
    "      - Auspatious\n",
    "    email: contact@fangyuan.space\n",
    "  - name: Alex Leith\n",
    "    affiliations:\n",
    "      - Auspatious\n",
    "    email: alex@auspatious.com\n",
    "\n",
    "keywords:\n",
    "  - GeoMAD\n",
    "  - Sentinel-2\n",
    "  - Open Data Cube\n",
    "  - Cloud Cover\n",
    "  - Indonesia\n",
    "  - Remote Sensing\n",
    "  - Earth Observation\n",
    "project:\n",
    "  license: CC-BY-4.0\n",
    "  open_access: true\n",
    "  github: https://github.com/your-repo/indonesia-geomad\n",
    "abstract: |\n",
    "  This notebook explores optimal cloud cover thresholds for generating \n",
    "  geoMAD (Geometric Median and Median Absolute Deviation) composites \n",
    "  over Indonesia using Sentinel-2 L2A data. We compare different cloud \n",
    "  cover filtering strategies (≤100%, ≤80%, ≤60%) to balance data quality, \n",
    "  temporal coverage, and storage requirements. Additionally, we evaluate \n",
    "  suitable study areas for testing and validation across Indonesia's \n",
    "  diverse geographic conditions.\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This notebook explores optimal cloud cover thresholds for generating geoMAD (Geometric Median and Median Absolute Deviation) composites over Indonesia using Sentinel-2 L2A data. We compare different cloud cover filtering strategies (≤100%, ≤80%, ≤60%) to balance data quality and temporal coverage. Additionally, we evaluate suitable study areas for testing and validation across various Indonesia's geographic conditions.\n",
    "\n",
    "## A. Objectives\n",
    "\n",
    "1. Evaluate data distribution and availability across Indonesia under different cloud cover thresholds (100%, 80%, 60%)\n",
    "\n",
    "2. Locate tiles with least datasets to serve as test subjects alongside tiles with diverse geographic conditions\n",
    "\n",
    "3. Test with Argo Workflows to document peak memory usage, especially on high-dataset tiles\n",
    "\n",
    "\n",
    "## B. Initial Setup\n",
    "### Libraries Used\n",
    "pandas\n",
    ": Python data analysis library for handling tabular data, dataframes, and statistical operations\n",
    "\n",
    "odc-stats\n",
    ": Open Data Cube statistics toolkit for generating temporal composites and summary statistics from Earth observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In piksel-sandbox, we need to upgrade odc-stats to the latest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade odc-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ODC-Stats Task Database\n",
    "\n",
    "> We use terminal commands to imitate the production workflow with odc-stats container.\n",
    "\n",
    "The function below generates task databases filtered by cloud cover threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tasks(cloud_cover, output_db):\n",
    "    \"\"\"Generate odc-stats task database with cloud cover filter.\"\"\"\n",
    "    !odc-stats save-tasks \\\n",
    "        --frequency \"annual\" \\\n",
    "        --grid \"EPSG:6933;10;5000\" \\\n",
    "        --year \"2024\" \\\n",
    "        --input-products \"s2_l2a\" \\\n",
    "        --dataset-filter='{{\"cloud_cover\": [0,{cloud_cover}]}}' \\\n",
    "        {output_db}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How save_tasks() Works\n",
    "\n",
    "When executed, the `save-tasks` command performs the following operations:\n",
    "\n",
    "1. **Query ODC Database** - Connects to the Open Data Cube and queries all indexed Sentinel-2 L2A datasets for the year 2024\n",
    "\n",
    "2. **Apply Cloud Cover Filter** - The function receives two arguments: `cloud_cover_threshold` and `output_filename`. It filters datasets based on the specified threshold:\n",
    "\n",
    "   ```python\n",
    "   save_tasks(60, \"tasks_cc60.db\")   # cloud_cover: [0, 60]\n",
    "   save_tasks(80, \"tasks_cc80.db\")   # cloud_cover: [0, 80]\n",
    "   save_tasks(100, \"tasks_cc100.db\") # cloud_cover: [0, 100]\n",
    "   ```\n",
    "   \n",
    "   - **First argument**: Maximum cloud cover percentage (60, 80, or 100)\n",
    "   - **Second argument**: Output filename prefix for generated files\n",
    "   - Filters include all datasets with cloud cover from 0% up to the specified threshold\n",
    "\n",
    "3. **Generate Spatial Grid** - Creates a processing grid in EPSG:6933 projection with 10° tiles at 5000m resolution covering Indonesia\n",
    "\n",
    "4. **Spatial Intersection** - Matches filtered datasets to their corresponding grid tiles based on spatial footprints\n",
    "\n",
    "5. **Task Generation** - For each tile, generates processing tasks containing:\n",
    "   - Tile identifier and spatial bounds\n",
    "   - List of datasets intersecting that tile\n",
    "   - Metadata for GeoMAD computation\n",
    "\n",
    "6. **Database Storage** - Serializes all tasks into multiple output formats:\n",
    "   - **`.db`** - SQLite database for efficient querying and task distribution\n",
    "   - **`.csv`** - Tabular summary of tiles and dataset counts\n",
    "   - **`.json`** - JSON manifest with complete task specifications\n",
    "\n",
    ":::{note}\n",
    "This process takes several minutes to complete.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function\n",
    "save_tasks(60, \"tasks_cc60.db\")\n",
    "save_tasks(80, \"tasks_cc80.db\")\n",
    "save_tasks(100, \"tasks_cc100.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_cc100 = pd.read_csv('tasks_cc100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSample tasks:\")\n",
    "print(tasks_cc100.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the CSV\n",
    "\n",
    "print(f\"Total tasks: {len(tasks_df)}\")\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(tasks_cc100.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
